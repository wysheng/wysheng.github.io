<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Python3网络爬虫(五)：爬取人物头像</title>
    <meta name="description" content="  （一）预备知识  (二)实战  (三) 总结运行平台：Windows Python版本：Python3.x IDE：Sublime text3（一）预备知识为了也能够学习到新知识，本次爬虫教程使用requests第三方库，这个库可不是Python3内置的urllib.request库，而是一个强大的基于url...">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2018/02/13/python6/">
    <link rel="alternate" type="application/rss+xml" title="王者勇胜" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?cf8506e0ef223e57ff6239944e5d46a4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72449510-4', 'auto');
      ga('send', 'pageview');

    </script>



</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/" class="brand">王者勇胜</a>
        <small>生活不止眼前的代码和苟且，还有诗和远方！</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/">
                    
                        <i class="fa fa-home"></i>主页
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>归档
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>目录
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>标签
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>收藏
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/life/">
                        
                            <i class="fa fa-heart"></i>我的诗词
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>关于我
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left">
        <h1>Python3网络爬虫(五)：爬取人物头像</h1>
        <div class="label">

            <div class="label-card">
                <i class="fa fa-calendar"></i>2018-02-13
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Python网络爬虫" title="Category: Python网络爬虫" rel="category">Python网络爬虫</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

            <div class="label-card">
            
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <!--a href="/tag/#Python" title="Tag: Python" rel="tag">Python</a-->
        <a href="/tag/#Python" title="Tag: Python" rel="tag">Python</a>&nbsp;
    
        <!--a href="/tag/#%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB" title="Tag: 网络爬虫" rel="tag">网络爬虫</a-->
        <a href="/tag/#网络爬虫" title="Tag: 网络爬虫" rel="tag">网络爬虫</a>
    
  

</span>

            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#一预备知识" id="markdown-toc-一预备知识">（一）预备知识</a></li>
  <li><a href="#二实战" id="markdown-toc-二实战">(二)实战</a></li>
  <li><a href="#三-总结" id="markdown-toc-三-总结">(三) 总结</a></li>
</ul>

<p>运行平台：Windows 
Python版本：Python3.x 
IDE：Sublime text3</p>
<h2 id="一预备知识">（一）预备知识</h2>
<p>为了也能够学习到新知识，本次爬虫教程使用requests第三方库，这个库可不是Python3内置的urllib.request库，而是一个强大的基于urllib3的第三方库</p>

<p>requests库的基础方法如下：</p>

<p><img src="https://img-blog.csdn.net/20170521121032110?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
官方中文教程地址：http://docs.python-requests.org/zh_CN/latest/user/quickstart.html</p>

<p>因为官方给出的《快速上手》教程已经整理的很好了，并且本次教程使用的也是最简单的requests.get()，因此第三方库requests的使用方法，不再累述。详情请看官方中文教程，有urllib2基础的人，还是好上手的。</p>

<h2 id="二实战">(二)实战</h2>
<p>2.1 背景
    爬取《帅啊》网的帅哥图片！</p>

<p>URL : http://www.shuaia.net/index.html</p>

<p>先看一眼网站的样子：
<img src="https://img-blog.csdn.net/20170521121231569?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></p>

<p>2.2 requests安装
    在cmd中，使用如下指令安装第三方库requests：
pip3 install requests
    或者：
easy_install requests
2.3 爬取单页目标连接
    通过审查元素，我们不难发现，目标的地址存储在class属性为”item-img”的<a>标签的href属性中。这时候，有人可能会问为啥不用下面的<img />标签的src属性？因为这个图片是首页的浏览图片，根据这个地址保存下来的图片，太小了，并且不清清楚。秉承着热爱“高清无码”的精神，这种图片可不是我想要的。因此，先获取目标的地址，也就是我们点击图片之后，进入的网页地址，然后根据下一个网页，找到图片的地址。
<img src="https://img-blog.csdn.net/20170521121440034?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 代码：</a></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> # -*- coding:UTF-8 -*-
from bs4 import BeautifulSoup
import requests

if __name__ == '__main__':
    url = 'http://www.shuaia.net/index.html'
    headers = {
            "User-Agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
    }
    req = requests.get(url = url,headers = headers)
    req.encoding = 'utf-8'
    html = req.text
    bf = BeautifulSoup(html, 'lxml')
    targets_url = bf.find_all(class_='item-img')
    list_url = []
    for each in targets_url:
        list_url.append(each.img.get('alt') + '=' + each.get('href'))
    print(list_url)
</code></pre></div></div>
<p>我们将爬取的信息保存到list中，图片名字和图片地址使用”=”连接，运行结果：
 <img src="https://img-blog.csdn.net/20170521121615323?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></p>

<p>2.4 爬取多页目标连接
    翻到第二页的时候，很容易就发现地址变为了:www.shuaia.net/index_2.html。第三页、第四页、第五页依此类推。
<img src="https://img-blog.csdn.net/20170521121727325?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
代码：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># -*- coding:UTF-8 -*-
from bs4 import BeautifulSoup
import requests

if __name__ == '__main__':
    list_url = []
    for num in range(1,20):
        if num == 1:
            url = 'http://www.shuaia.net/index.html'
        else:
            url = 'http://www.shuaia.net/index_%d.html' % num
        headers = {
                "User-Agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        }
        req = requests.get(url = url,headers = headers)
        req.encoding = 'utf-8'
        html = req.text
        bf = BeautifulSoup(html, 'lxml')
        targets_url = bf.find_all(class_='item-img')

        for each in targets_url:
            list_url.append(each.img.get('alt') + '=' + each.get('href'))
    print(list_url)
</code></pre></div></div>
<p>我们少爬取一些，爬取前19页的目标连接：
<img src="https://img-blog.csdn.net/20170521121837177?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
2.5 单张图片下载
    进入目标地址，审查元素。可以看到，图片地址保存在了class属性为”wr-single-content-list “的div-&gt;div-&gt;img的src属性中。
<img src="https://img-blog.csdn.net/20170521121936116?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 代码：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> target_url = 'http://www.shuaia.net/rihanshuaige/2017-05-18/1294.html'
filename = '张根硕拍摄机车型男写真帅气十足' + '.jpg'
headers = {
    "User-Agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
    }
img_req = requests.get(url = target_url,headers = headers)
img_req.encoding = 'utf-8'
img_html = img_req.text
img_bf_1 = BeautifulSoup(img_html, 'lxml')
img_url = img_bf_1.find_all('div', class_='wr-single-content-list')
img_bf_2 = BeautifulSoup(str(img_url), 'lxml')
img_url = 'http://www.shuaia.net' + img_bf_2.div.img.get('src')
if 'images' not in os.listdir():
    os.makedirs('images')
urlretrieve(url = img_url,filename = 'images/' + filename)
print('下载完成！')
</code></pre></div></div>
<p>我们将图片保存在程序文件所在目录的imgase目录下：
 <img src="https://img-blog.csdn.net/20170521122107585?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 <img src="https://img-blog.csdn.net/20170521122141523?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 2.6 整体代码
已经获取到了每张图片的连接，我们就可以下载了。整合下代码，先少下载一点，下载前2页的图片。</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># -*- coding:UTF-8 -*-
from bs4 import BeautifulSoup
from urllib.request import urlretrieve
import requests
import os
import time

if __name__ == '__main__':
    list_url = []
    for num in range(1,3):
        if num == 1:
            url = 'http://www.shuaia.net/index.html'
        else:
            url = 'http://www.shuaia.net/index_%d.html' % num
        headers = {
                "User-Agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        }
        req = requests.get(url = url,headers = headers)
        req.encoding = 'utf-8'
        html = req.text
        bf = BeautifulSoup(html, 'lxml')
        targets_url = bf.find_all(class_='item-img')

        for each in targets_url:
            list_url.append(each.img.get('alt') + '=' + each.get('href'))

    print('连接采集完成')

    for each_img in list_url:
        img_info = each_img.split('=')
        target_url = img_info[1]
        filename = img_info[0] + '.jpg'
        print('下载：' + filename)
        headers = {
            "User-Agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        }
        img_req = requests.get(url = target_url,headers = headers)
        img_req.encoding = 'utf-8'
        img_html = img_req.text
        img_bf_1 = BeautifulSoup(img_html, 'lxml')
        img_url = img_bf_1.find_all('div', class_='wr-single-content-list')
        img_bf_2 = BeautifulSoup(str(img_url), 'lxml')
        img_url = 'http://www.shuaia.net' + img_bf_2.div.img.get('src')
        if 'images' not in os.listdir():
            os.makedirs('images')
        urlretrieve(url = img_url,filename = 'images/' + filename)
        time.sleep(1)

    print('下载完成！')
</code></pre></div></div>
<p>运行结果如下：
<img src="https://img-blog.csdn.net/20170521122323428?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
最终下载的图片：
<img src="https://img-blog.csdn.net/20170521122401947?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></p>

<h2 id="三-总结">(三) 总结</h2>
<p>    图片是不是很帅？还算满意吧？
    这种爬取方法是比较简单的，速度慢。服务器有防爬虫程序，所以不能爬太快，每下载一个图片需要加个1秒延时，否则会被服务器断开连接。当然，解决办法还是有的，因为不是本文重点，以后有机会再细说。
    爬取图片的原理就是这样了，如果想爬取妹子图的可以去《煎蛋网》看看，包你满意。</p>


        </article>
        <hr>

        
        
            
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <h2 id="similar_posts">Similar Posts</h2>
                        <ul>
                        
                        <li class="relatedPost">
                            <a href="/2018/02/13/python7/">Python3网络爬虫(五)：爬取人物头像
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2018/01/11/python5/">Python3网络爬虫(四)：Python3安装Scrapy
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2017/05/22/python4/">Python3网络爬虫(三)：使用User Agent和代理IP隐藏身份
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2017/05/22/python3/">Python3网络爬虫(二)：利用urllib.urlopen向有道翻译发送数据获得翻译结果
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
        
            </ul>
        

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2018/02/01/Hive2/">Hive的几种常见的数据导入方式</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2018/02/13/python7/">Python3网络爬虫(五)：爬取人物头像</a></p>
        
    </div>
</div>


        <h2 id="comments">Comments</h2>
        


<div id="disqus_thread"></div>
<script>
    /**
     * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */

    var disqus_config = function() {
        this.page.url = 'http://localhost:4000/2018/02/13/python6/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://localhost:4000/2018/02/13/python6/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document,
            s = d.createElement('script');

        s.src = '//wysheng.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>




    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#similar_posts">Similar Posts</a></li>
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id])')
    for (var i = 0; i < aTags.length; i++) {
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>


    <footer class="site-footer">


    <div class="wrapper">

        <p class="description">
             好好学习，天天向上！ 
        </p>
        <p class="contact">
            Contact me at: 
            <a href="https://github.com/wysheng" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:wyshengcn@163.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>        
        </p>
        <p>
            本站总访问量<span id="busuanzi_value_site_pv"></span>次，本站访客数<span id="busuanzi_value_site_uv"></span>人次，本文总阅读量<span id="busuanzi_value_page_pv"></span>次
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
    <!-- <script src=" /js/scroll.min.js " charset="utf-8"></script> -->
  </body>

</html>
