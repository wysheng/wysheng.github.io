<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Python3网络爬虫(四)：Python3安装Scrapy</title>
    <meta name="description" content="  一、Scrapy简介运行平台：Windows Python版本：Python3.x IDE：Sublime text3一、Scrapy简介    Scrapy是一个为了爬取网站数据提取结构性数据而编写的应用框架，可以应用于数据挖掘，信息处理或存储历史数据等一些列的程序中。Scrapy最初就是为了网络爬取而设计...">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2018/01/11/python5/">
    <link rel="alternate" type="application/rss+xml" title="王者勇胜" href="http://localhost:4000/feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?cf8506e0ef223e57ff6239944e5d46a4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    <script>
    // google analytics
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72449510-4', 'auto');
      ga('send', 'pageview');

    </script>



</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/" class="brand">王者勇胜</a>
        <small>生活不止眼前的代码和苟且，还有诗和远方！</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/">
                    
                        <i class="fa fa-home"></i>主页
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>归档
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>目录
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>标签
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>收藏
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/life/">
                        
                            <i class="fa fa-heart"></i>我的诗词
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>关于我
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left">
        <h1>Python3网络爬虫(四)：Python3安装Scrapy</h1>
        <div class="label">

            <div class="label-card">
                <i class="fa fa-calendar"></i>2018-01-11
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Python网络爬虫" title="Category: Python网络爬虫" rel="category">Python网络爬虫</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

            <div class="label-card">
            
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <!--a href="/tag/#Python" title="Tag: Python" rel="tag">Python</a-->
        <a href="/tag/#Python" title="Tag: Python" rel="tag">Python</a>&nbsp;
    
        <!--a href="/tag/#%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB" title="Tag: 网络爬虫" rel="tag">网络爬虫</a-->
        <a href="/tag/#网络爬虫" title="Tag: 网络爬虫" rel="tag">网络爬虫</a>
    
  

</span>

            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <ul id="markdown-toc">
  <li><a href="#一scrapy简介" id="markdown-toc-一scrapy简介">一、Scrapy简介</a></li>
</ul>

<p>运行平台：Windows 
Python版本：Python3.x 
IDE：Sublime text3</p>
<h2 id="一scrapy简介">一、Scrapy简介</h2>

<p>    Scrapy是一个为了爬取网站数据提取结构性数据而编写的应用框架，可以应用于数据挖掘，信息处理或存储历史数据等一些列的程序中。Scrapy最初就是为了网络爬取而设计的。现在，Scrapy已经推出了曾承诺过的Python3.x版本。</p>

<p>    为什么学习Scrapy呢？它能我们更好的完成爬虫任务，自己写Python爬虫程序好比孤军奋战，而使用了Scrapy就好比手底下有了千军万马。Scrapy可以起到事半功倍(甚至好几倍<em>.</em>)的效果。所以，学习Scrapy也就显得很有必要了。</p>

<p>二、Scrapy安装</p>

<p>    1.直接使用指令pip3 install scrapy，发现有诸多错误。</p>

<p>Failed building wheel for lxml
Microsoft Visual C++ 10.0 is required
Failed building twisted
Unable to find vcvarsall.bat
    遇到的错误，如下图所示：
<img src="https://img-blog.csdn.net/20170303232553247?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
<img src="https://img-blog.csdn.net/20170303232540981?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
<img src="https://img-blog.csdn.net/20170303232629888?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></p>

<p>2.解决办法</p>

<p>    在http://www.lfd.uci.edu/~gohlke/pythonlibs/有很多用于windows的编译好的Python第三方库，我们下载好对应自己Python版本的库即可。</p>

<p>    (1)在cmd中输入指令python，查看python的版本，如下：
<img src="https://img-blog.csdn.net/20170303232721966?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
从上图可以看出可以看出我的Python版本为Python3.5.2-64bit。</p>

<p>    (2)登陆http://www.lfd.uci.edu/~gohlke/pythonlibs/，Ctrl+F搜索Lxml、Twisted、Scrapy，下载对应的版本，例如：lxml-3.7.3-cp35-cp35m-win_adm64.whl，表示lxml的版本为3.7.3，对应的python版本为3.5-64bit。我下载的版本如下图所示：
<img src="https://img-blog.csdn.net/20170303233515040?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
<img src="https://img-blog.csdn.net/20170303232806890?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
<img src="https://img-blog.csdn.net/20170303232817859?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 (3)在cmd中输入DOS指令，进入下载好的whl文件夹下，例如我的三个whl文件放在了Scrapy文件夹下：
 <img src="https://img-blog.csdn.net/20170303232903170?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
 (4)依次执行如下命令：
 a.pip3 install wheel
 b.pip3 install lxml-3.7.3-cp35-cp35m-win_amd64.whl
 c.pip3 install Twisted-17.1.0-cp35-cp35m-win_amd64.whl
 d.pip3 install Scrapy-1.3.2-py2.py3-none-any.whl
 这样Scrapy的安装就完成了，请忽略最后两行让我升级pip的信息。<em>.</em></p>

<p>    (5)Srapy已经安装成功，还要下载pywin32，找到对应版本下载，一路下一步安装即可。安装完成后，就可以正常使用Scrapy了。</p>

<p><img src="https://img-blog.csdn.net/20170303233239661?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYzQwNjQ5NTc2Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />
   至此，大功告成，我们可以愉快的使用Scrapy了。</p>


        </article>
        <hr>

        
        
            
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <h2 id="similar_posts">Similar Posts</h2>
                        <ul>
                        
                        <li class="relatedPost">
                            <a href="/2018/02/13/python7/">Python3网络爬虫(五)：爬取人物头像
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2018/02/13/python6/">Python3网络爬虫(五)：爬取人物头像
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2017/05/22/python4/">Python3网络爬虫(三)：使用User Agent和代理IP隐藏身份
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2017/05/22/python3/">Python3网络爬虫(二)：利用urllib.urlopen向有道翻译发送数据获得翻译结果
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
            
                
                    
                
                    
                
            
        
        
            </ul>
        

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>上一篇</strong> <a href="/2017/09/16/1-Algorams3/">剑指offer:链表中倒数第k个节点</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>下一篇</strong> <a href="/2018/02/01/Hive1/">Hive的几种常见的数据导入方式</a></p>
        
    </div>
</div>


        <h2 id="comments">Comments</h2>
        


<div id="disqus_thread"></div>
<script>
    /**
     * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */

    var disqus_config = function() {
        this.page.url = 'http://localhost:4000/2018/01/11/python5/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://localhost:4000/2018/01/11/python5/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document,
            s = d.createElement('script');

        s.src = '//wysheng.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>




    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#similar_posts">Similar Posts</a></li>
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id])')
    for (var i = 0; i < aTags.length; i++) {
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>


    <footer class="site-footer">


    <div class="wrapper">

        <p class="description">
             好好学习，天天向上！ 
        </p>
        <p class="contact">
            Contact me at: 
            <a href="https://github.com/wysheng" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:wyshengcn@163.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>        
        </p>
        <p>
            本站总访问量<span id="busuanzi_value_site_pv"></span>次，本站访客数<span id="busuanzi_value_site_uv"></span>人次，本文总阅读量<span id="busuanzi_value_page_pv"></span>次
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
    <!-- <script src=" /js/scroll.min.js " charset="utf-8"></script> -->
  </body>

</html>
